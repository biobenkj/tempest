# Custom Tempest Configuration for Complex Read Architecture with Probabilistic PWM
# Sequence structure: p7, i7, RP2, UMI, ACC, cDNA, polyA, CBC, RP1, i5, p5

# Model Architecture Configuration
model:
  max_seq_len: 1500  # Increased for complex architecture
  num_labels: 11     # p7, i7, RP2, UMI, ACC, cDNA, polyA, CBC, RP1, i5, p5
  embedding_dim: 128
  lstm_units: 256
  lstm_layers: 2
  dropout: 0.3
  use_cnn: true
  use_bilstm: true
  batch_size: 32
  vocab_size: 5  # A, C, G, T, N
  cnn_filters: [64, 128]
  cnn_kernels: [3, 5]
  use_crf: true  # Add this for CRF layer

# Data Simulation Configuration
simulation:
  # Number of sequences to generate
  num_sequences: 50000  # Larger dataset for complex architecture
  train_split: 0.8

  # Introduce invalid reads
  invalid_fraction: 0.1
  invalid_types: ["segment_loss", "segment_duplication", "truncation", "chimeric", "scrambled"]
  invalid_params:
    segment_loss_prob: 0.2
    segment_dup_prob: 0.2
    truncated_prob: 0.2
    chimeric_prob: 0.2
    scrambled_prob: 0.2
  
  # Additional test/validation splits
  n_train: 40000
  n_val: 5000
  n_test: 5000
  
  # Random seed for reproducibility
  random_seed: 42
  
  # Sequence architecture - your specific read structure
  sequence_order:
    - p7
    - i7
    - RP2
    - UMI
    - ACC
    - cDNA
    - polyA
    - CBC
    - RP1
    - i5
    - p5
  
  # Enable full read reverse complement to simulate bidirectional sequencing
  full_read_reverse_complement_prob: 0.5
  
  # Fixed sequences for adapters and primers
  sequences:
    p7: "CAAGCAGAAGACGGCATACGAGAT"
    RP2: "GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT"
    RP1: "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"
    p5: "GTGTAGATCTCGGTGGTCGCCGTATCATT"
    UMI: "random"       # Will generate NNNNNNNN
    cDNA: "transcript"  # Will use transcript pool
    polyA: "polya"      # Will use polyA generator
    # i7, i5, ACC, CBC will use whitelists/PWM
  
  # Whitelist files
  whitelist_files:
    i7: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/udi_i7.txt"
    i5: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/udi_i5.txt"
    CBC: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/cbc.txt"
  
  # PWM configuration for ACC - USING PROBABILISTIC APPROACH
  pwm_files:
    ACC: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/acc_pwm.txt"
  
  # Probabilistic PWM parameters for ACC generation
  pwm:
    pwm_file: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/acc_pwm.txt"
    temperature: 1.2  # Moderate diversity for realistic ACC sequences
    min_entropy: 0.1  # Ensures at least 10% entropy at each position
    diversity_boost: 1.0  # Can be increased for more varied test sets
    pattern: "ACCSSV"  # IUPAC pattern for ACC
  
  # Segment generation parameters
  segment_generation:
    lengths:
      p7: 24
      i7: 8
      RP2: 34
      UMI: 8
      ACC: 6
      cDNA: 500
      polyA: 30
      CBC: 6
      RP1: 33
      i5: 8
      p5: 29
    
    generation_mode:
      p7: "fixed"
      i7: "whitelist"
      RP2: "fixed"
      UMI: "random"
      ACC: "pwm"
      cDNA: "transcript"
      polyA: "polya"
      CBC: "whitelist"
      RP1: "fixed"
      i5: "whitelist"
      p5: "fixed"
  
  # Segment length ranges
  sequence_lengths:
    p7: {min: 24, max: 24}
    i7: {min: 8, max: 8}
    RP2: {min: 34, max: 34}
    UMI: {min: 8, max: 8}
    ACC: {min: 6, max: 6}
    cDNA: {min: 200, max: 1000}
    polyA: {min: 10, max: 50}
    CBC: {min: 6, max: 6}
    RP1: {min: 33, max: 33}
    i5: {min: 8, max: 8}
    p5: {min: 29, max: 29}
  
  # Transcript configuration for cDNA segments
  transcript:
    fasta_file: "gencode.v49.transcripts.fa.gz"
    min_length: 200
    max_length: 5000
    fragment_mode: true
    fragment_min: 200
    fragment_max: 1000
    trim_polya: true
  
  # PolyA tail configuration
  polya_tail:
    min_length: 10
    max_length: 50
    purity: 0.95
    distribution: "normal"
    mean: 30
    std: 10
  
  # Error simulation parameters
  error_injection:
    enabled: true
    substitution_rate: 0.001
    insertion_rate: 0.0001
    deletion_rate: 0.0001
    homopolymer_error_rate: 0.002

# Training Configuration
training:
  epochs: 50
  batch_size: 32
  learning_rate: 0.001
  optimizer: "adam"
  train_split: 0.8  # Add this since simulation references it
  
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.0001
    monitor: "val_loss"
    restore_best: true
  
  use_class_weights: true
  
  checkpoint:
    enabled: true
    save_best_only: true
    monitor: "val_loss"
    save_freq: "epoch"
  
  tensorboard:
    enabled: true
    log_dir: "./logs"
    histogram_freq: 0
    write_graph: true
    update_freq: "epoch"
  
  # Learning rate scheduler
  lr_scheduler:
    enabled: true
    type: "reduce_on_plateau"
    factor: 0.5
    patience: 5
    min_lr: 0.00001

# Hybrid Training Configuration
hybrid:
  enabled: true
  
  # Training phases for hybrid models
  warmup_epochs: 10        # Phase 1: Standard training
  discriminator_epochs: 10 # Phase 2: Adversarial with invalid reads
  pseudolabel_epochs: 10   # Phase 3: Pseudo-labeling with unlabeled data
  
  # Invalid read generation for robustness
  invalid_generation:
    enabled: true
    invalid_fraction: 0.2
    augmentation_prob: 0.3
  
  # Pseudo-labeling configuration
  pseudolabel:
    enabled: true
    confidence_threshold: 0.9
    max_samples: 10000
    update_frequency: 5  # Update pseudo-labels every N epochs
  
  # Discriminator configuration for adversarial training
  discriminator:
    enabled: true
    architecture: "simple"  # 'simple' or 'complex'
    learning_rate: 0.001
    weight: 0.5  # Weight of discriminator loss
  
  # Constraint configurations
  length_constraints:
    enabled: true
    enforce_during_training: true
    enforce_during_inference: true
    segments:
      p7: [24, 24]
      i7: [8, 8]
      RP2: [34, 34]
      UMI: [8, 8]
      ACC: [6, 6]
      CBC: [6, 6]
      RP1: [33, 33]
      i5: [8, 8]
      p5: [29, 29]
  
  whitelist_constraints:
    enabled: true
    segments: ["i7", "i5", "CBC"]
    enforce_during_training: true
    enforce_during_inference: true
  
  pwm_constraints:
    enabled: true
    segments: ["ACC"]
    use_probabilistic_scoring: true
    scoring_method: "log_likelihood"
    min_score: -10.0
    score_weight: 0.5

# Enhanced Ensemble Configuration
ensemble:
  enabled: true
  num_models: 5  # Total number of models in ensemble
  
  # Model type configuration (NEW)
  # Option 1: Specify exact types for each model
  # model_types: ["standard", "hybrid", "standard", "hybrid", "standard"]
  
  # Option 2: Use ratio to automatically determine types
  hybrid_ratio: 0.4  # 40% hybrid models, 60% standard models
  
  # If unlabeled data path is provided at runtime, it will be used for hybrid models
  # unlabeled_data_path: "path/to/unlabeled.fastq"  # Can be set at runtime
  
  # Variation configuration
  variation_type: "both"  # 'architecture', 'initialization', or 'both'
  
  # Architecture variations for diversity
  architecture_variations:
    vary_lstm_units: [128, 256, 512]
    vary_lstm_layers: [2, 3]
    vary_dropout: [0.2, 0.3, 0.4, 0.5]
    vary_embedding_dim: [64, 128, 256]
    vary_cnn_filters: [[64, 128], [128, 256], [32, 64, 128]]
  
  # Initialization variations
  random_seeds: [42, 123, 456, 789, 1011]
  
  # Bayesian Model Averaging (BMA) Configuration
  bma_prior: "performance"  # 'uniform' or 'performance'
  bma_temperature: 1.0  # Temperature for softmax when using performance-based weights
  
  # BMA weight computation
  bma_config:
    method: "validation_accuracy"  # Use validation accuracy for weights
    min_weight: 0.01  # Minimum weight for any model
    normalize: true  # Ensure weights sum to 1
    
    # Performance metrics to consider
    metrics_weights:
      val_accuracy: 0.7
      val_loss: 0.3
    
    # Optional: different weights for different model types
    type_bonus:
      hybrid: 1.1  # Give 10% bonus to hybrid models if they use unlabeled data
      standard: 1.0
  
  # Prediction aggregation
  prediction_aggregation:
    method: "weighted_average"  # 'weighted_average', 'voting', 'stacking'
    confidence_weighting: true
    uncertainty_estimation: true
  
  # Calibration for ensemble predictions
  calibration:
    enabled: true
    method: "isotonic"  # 'isotonic', 'platt', 'temperature_scaling'
    calibration_split: 0.2  # Use 20% of validation for calibration
  
  # Diversity metrics and enforcement
  diversity:
    measure: "disagreement"  # 'disagreement', 'correlation', 'kl_divergence'
    min_diversity: 0.1  # Minimum required diversity
    enforce: true  # Enforce diversity during training
  
  # Ensemble evaluation
  evaluation:
    compute_individual_metrics: true
    compute_ensemble_metrics: true
    metrics: ["accuracy", "f1", "segment_accuracy", "calibration_error"]
    analyze_model_contributions: true
    
    # Model selection criteria (if you want to select subset)
    selection:
      enabled: false  # Set to true to select best subset
      method: "greedy"  # 'greedy', 'genetic', 'exhaustive'
      metric: "val_accuracy"
      max_models: 3  # Select best 3 models
  
  # Uncertainty quantification
  uncertainty:
    compute_epistemic: true  # Model uncertainty
    compute_aleatoric: true  # Data uncertainty
    method: "ensemble_variance"  # How to compute uncertainty
    confidence_level: 0.95
  
  # Save configuration
  save:
    save_all_models: true
    save_ensemble_metadata: true
    save_predictions: true
    checkpoint_frequency: 5  # Save ensemble checkpoint every N epochs

# Evaluation Configuration
evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1"
    - "segment_accuracy"
    - "edit_distance"
    - "boundary_accuracy"
    - "acc_diversity"
    - "acc_score_distribution"
  
  per_segment_metrics: true
  
  confusion_matrix:
    enabled: true
    normalize: true
  
  error_analysis:
    enabled: true
    sample_errors: 100
    save_errors: true
  
  acc_evaluation:
    enabled: true
    compute_entropy: true
    compute_divergence: true
    save_acc_sequences: true

# Visualization Configuration
visualization:
  enabled: true
  plots:
    - "training_curves"
    - "confusion_matrix"
    - "segment_performance"
    - "length_distribution"
    - "error_patterns"
    - "model_comparison"
    - "ensemble_weights"  # NEW: Visualize BMA weights
    - "model_diversity"   # NEW: Visualize model disagreement
    - "acc_pwm_heatmap"
    - "acc_sequence_logo"
    - "acc_score_histogram"
  
  save_plots: true
  plot_dir: "./plots"

# Demultiplexing Configuration
demux:
  # Sequence architecture - your specific read structure
  sequence_order:
    - p7
    - i7
    - RP2
    - UMI
    - ACC
    - cDNA
    - polyA
    - CBC
    - RP1
    - i5
    - p5
  
  # Model path
  # Usually will be a trained model derived from above train command
  model_path: "/path/to/model.h5"

  # Set the minimum edit distance allowed
  edit_distance:
    i7: 2
    i5: 2
    CBC: 1
  
  # Whitelist files
  whitelist_files:
    i7: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/udi_i7.txt"
    i5: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/udi_i5.txt"
    CBC: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/cbc.txt"
  
  # Sample file
  # Must be tab delimited and have the configuration of 'sample_id', 'CBC', 'i5', 'i7'
  sample_file: "/path/to/sample_file.txt"

  # How to save the files
  save_fastq: true
  save_fasta: false
  output_dir: "/path/to/demux/dir"

# Logging Configuration
logging:
  level: "INFO"
  log_to_file: true
  log_file: "./tempest_training.log"
  log_whitelist_usage: true
  log_generation_stats: true
  log_pwm_stats: true
  log_ensemble_progress: true  # NEW: Log ensemble training progress

# Output Configuration
output:
  save_dir: "./tempest_output"
  save_predictions: true
  save_model: true
  save_config: true
  create_report: true
  save_acc_analysis: true
  save_ensemble_analysis: true  # NEW: Save ensemble-specific analysis
