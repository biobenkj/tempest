# Custom Tempest Configuration for Complex Read Architecture with Probabilistic PWM
# Sequence structure: p7, i7, RP2, UMI, ACC, cDNA, polyA, CBC, RP1, i5, p5

# Model Architecture Configuration
model:
  max_seq_len: 1500  # Increased for complex architecture
  num_labels: 11     # p7, i7, RP2, UMI, ACC, cDNA, polyA, CBC, RP1, i5, p5
  embedding_dim: 128
  lstm_units: 256
  lstm_layers: 2
  dropout: 0.3
  use_cnn: true
  use_bilstm: true
  batch_size: 32

# Data Simulation Configuration
simulation:
  # Number of sequences to generate
  num_sequences: 50000  # Larger dataset for complex architecture
  train_split: 0.8
  
  # Additional test/validation splits
  n_train: 40000
  n_val: 5000
  n_test: 5000
  
  # Random seed for reproducibility
  random_seed: 42
  
  # Sequence architecture - your specific read structure
  sequence_order:
    - p7
    - i7
    - RP2
    - UMI
    - ACC
    - cDNA
    - polyA
    - CBC
    - RP1
    - i5
    - p5
  
  # Enable full read reverse complement to simulate bidirectional sequencing
  full_read_reverse_complement_prob: 0.5
  
  # Fixed sequences for adapters and primers
  sequences:
    p7: "CAAGCAGAAGACGGCATACGAGAT"
    RP2: "GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT"
    RP1: "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"
    p5: "GTGTAGATCTCGGTGGTCGCCGTATCATT"
    UMI: "random"       # Will generate NNNNNNNN
    cDNA: "transcript"  # Will use transcript pool
    polyA: "polya"      # Will use polyA generator
    # i7, i5, ACC, CBC will use whitelists/PWM
  
  # Whitelist files
  whitelist_files:
    i7: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/udi_i7.txt"
    i5: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/udi_i5.txt"
    CBC: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/cbc.txt"
  
  # PWM configuration for ACC - USING PROBABILISTIC APPROACH
  pwm_files:
    ACC: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/acc_pwm.txt"
  
  # Probabilistic PWM parameters for ACC generation
  pwm:
    pwm_file: "/varidata/research/projects/shen/tools/benkj/tempest/whitelist/acc_pwm.txt"
    # Temperature controls diversity of generated sequences
    # Lower values (0.5-1.0): More conservative, closer to consensus
    # Higher values (1.5-2.0): More diverse, allows more variation
    temperature: 1.2  # Moderate diversity for realistic ACC sequences
    # Minimum entropy at each position to maintain some randomness
    min_entropy: 0.1  # Ensures at least 10% entropy at each position
    # Optional: boost diversity temporarily for specific generation tasks
    diversity_boost: 1.0  # Can be increased for more varied test sets
    # Pattern fallback if PWM file not found
    pattern: "ACCSSV"  # IUPAC pattern for ACC
  
  # Segment generation parameters
  segment_generation:
    lengths:
      p7: 24
      i7: 8     # From whitelist
      RP2: 34
      UMI: 8
      ACC: 6    # From PWM (6 positions)
      cDNA: 500 # Average length
      polyA: 30 # Average polyA length
      CBC: 6    # From whitelist
      RP1: 33
      i5: 8     # From whitelist
      p5: 29
    
    # Generation mode for each segment
    generation_mode:
      p7: "fixed"
      i7: "whitelist"
      RP2: "fixed"
      UMI: "random"
      ACC: "pwm"
      cDNA: "transcript"
      polyA: "polya"
      CBC: "whitelist"
      RP1: "fixed"
      i5: "whitelist"
      p5: "fixed"
  
  # Segment length ranges
  sequence_lengths:
    p7:
      min: 24
      max: 24
    i7:
      min: 8
      max: 8
    RP2:
      min: 34
      max: 34
    UMI:
      min: 8
      max: 8
    ACC:
      min: 6
      max: 6
    cDNA:
      min: 200
      max: 1000
    polyA:
      min: 10
      max: 50
    CBC:
      min: 6
      max: 6
    RP1:
      min: 33
      max: 33
    i5:
      min: 8
      max: 8
    p5:
      min: 29
      max: 29
  
  # Transcript configuration for cDNA segments
  transcript:
    fasta_file: "gencode.v49.transcripts.fa.gz"  # Will need to be downloaded/provided
    min_length: 200
    max_length: 5000
    fragment_mode: true
    fragment_min: 200
    fragment_max: 1000
    trim_polya: true
  
  # PolyA tail configuration
  polya_tail:
    min_length: 10
    max_length: 50
    purity: 0.95  # 95% A bases, 5% errors
    distribution: "normal"  # Normal distribution of lengths
    mean: 30
    std: 10
  
  # Error simulation parameters
  error_injection:
    enabled: true
    substitution_rate: 0.001
    insertion_rate: 0.0001
    deletion_rate: 0.0001
    homopolymer_error_rate: 0.002
  
  # Complexity parameters
  complexity:
    gc_bias:
      enabled: false
    quality_degradation:
      enabled: false

# Training Configuration
training:
  epochs: 50
  batch_size: 32
  learning_rate: 0.001
  optimizer: "adam"
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.0001
  
  # Class weights for imbalanced segments
  use_class_weights: true
  
  # Checkpoint configuration
  checkpoint:
    save_best_only: true
    monitor: "val_loss"
  
  # TensorBoard logging
  tensorboard:
    enabled: true
    log_dir: "./logs"

# Hybrid Training Configuration
hybrid:
  enabled: true
  
  # Constrained decoding parameters
  constrained_decoding:
    enabled: true
    method: "beam_search"
    beam_width: 5
    max_iterations: 100
  
  # Length constraints
  length_constraints:
    enabled: true
    enforce_during_training: true
    enforce_during_inference: true
  
  # Whitelist constraints
  whitelist_constraints:
    enabled: true
    segments:
      - i7
      - i5
      - CBC
    enforce_during_training: true
    enforce_during_inference: true
  
  # PWM constraints - NOW USING PROBABILISTIC SCORING
  pwm_constraints:
    enabled: true
    segments:
      - ACC
    # Instead of hard threshold, use probabilistic scoring
    use_probabilistic_scoring: true
    # Scoring parameters for ACC validation
    scoring_method: "log_likelihood"  # Options: log_likelihood, geometric_mean, min_probability
    # Optional: minimum score for accepting a sequence (soft constraint)
    min_score: -10.0  # Log likelihood threshold (more negative = more permissive)
    # For training: weight of PWM score in loss function
    score_weight: 0.5
    # For generation: already handled by temperature in pwm section above
  
  # Transition constraints
  transition_constraints:
    enabled: true
    enforce_order: true  # Enforce segment order
    allow_missing: false # Don't allow missing segments

# Ensemble Configuration
ensemble:
  enabled: true
  num_models: 3  # Number of models in ensemble
  
  # Model specifications
  models:
    - name: "standard_crf"
      type: "crf"
      weight: 0.3
      architecture_params:
        lstm_units: 256
        lstm_layers: 2
        dropout: 0.3
    - name: "hybrid_crf"
      type: "hybrid"
      weight: 0.4
      architecture_params:
        lstm_units: 256
        lstm_layers: 2
        dropout: 0.35
        use_constraints: true
    - name: "length_constrained"
      type: "length_constrained"
      weight: 0.3
      architecture_params:
        lstm_units: 256
        lstm_layers: 2
        dropout: 0.3
        constraint_weight: 1.0
  
  # Ensemble method selection
  voting_method: "bayesian_model_averaging"
  
  # Bayesian Model Averaging (BMA) Configuration
  bma_config:
    enabled: true
    prior_type: "uniform"
    prior_weights:
      standard_crf: 0.25
      hybrid_crf: 0.50
      length_constrained: 0.25
    approximation: "bic"
    approximation_params:
      bic:
        penalty_factor: 1.0
      laplace:
        num_samples: 1000
        damping: 0.01
      variational:
        num_iterations: 100
        learning_rate: 0.01
        convergence_threshold: 1e-4
      cross_validation:
        num_folds: 5
        stratified: true
    temperature: 1.0
    compute_posterior_variance: true
    normalize_posteriors: true
    min_posterior_weight: 0.01
    selection_criteria:
      use_model_averaging: true
      evidence_threshold: 0.05
  
  # Simple weighted average configuration
  weighted_average_config:
    optimization: "fixed"
    fixed_weights:
      standard_crf: 0.3
      hybrid_crf: 0.4
      length_constrained: 0.3
    optimization_params:
      grid_search:
        weight_resolution: 0.1
      differential_evolution:
        population_size: 20
        max_iterations: 100
        convergence_tol: 1e-4
      bayesian_optimization:
        num_initial_points: 10
        num_iterations: 50
        acquisition_function: "ei"
  
  # Prediction aggregation
  prediction_aggregation:
    method: "probability_averaging"
    confidence_weighting: true
    apply_temperature_scaling: false
    temperature_scaling_params:
      learn_temperature: true
      initial_temperature: 1.0
  
  # Calibration
  calibration:
    enabled: true
    method: "isotonic"
    calibration_params:
      isotonic:
        y_min: 0.0
        y_max: 1.0
        increasing: true
      platt:
        max_iterations: 100
        solver: "lbfgs"
      beta:
        num_bins: 15
      temperature_scaling:
        learn_temperature: true
        optimization_metric: "nll"
    use_separate_calibration_set: true
    calibration_split: 0.2
  
  # Model diversity enforcement
  diversity:
    enforce_diversity: true
    diversity_metric: "disagreement"
    min_diversity_threshold: 0.1
    vary_architecture: true
    architecture_variations:
      - lstm_units: [128, 256, 512]
      - dropout: [0.2, 0.3, 0.4]
      - lstm_layers: [2, 3]
    vary_initialization: true
    random_seeds: [42, 123, 456, 789, 1011]
    vary_training: false
    training_variations:
      - learning_rate: [0.001, 0.0005]
      - batch_size: [32, 64]
  
  # Uncertainty quantification
  uncertainty:
    compute_epistemic: true
    compute_aleatoric: true
    confidence_intervals: true
    interval_alpha: 0.05
  
  # Ensemble evaluation metrics
  evaluation:
    compute_ensemble_metrics: true
    metrics:
      - "accuracy"
      - "nll"
      - "brier_score"
      - "ece"
      - "diversity"
    analyze_model_contributions: true
    compute_shapley_values: false

# Evaluation Configuration
evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1"
    - "segment_accuracy"
    - "edit_distance"
    - "boundary_accuracy"
    # Add PWM-specific metrics
    - "acc_diversity"  # Measure diversity of generated ACC sequences
    - "acc_score_distribution"  # Distribution of PWM scores
  
  # Segment-specific evaluation
  per_segment_metrics: true
  
  # Confusion matrix
  confusion_matrix:
    enabled: true
    normalize: true
  
  # Error analysis
  error_analysis:
    enabled: true
    sample_errors: 100
    save_errors: true
  
  # ACC-specific evaluation
  acc_evaluation:
    enabled: true
    compute_entropy: true  # Measure entropy of generated ACC sequences
    compute_divergence: true  # KL divergence from expected PWM distribution
    save_acc_sequences: true  # Save all generated ACC sequences for analysis

# Visualization Configuration
visualization:
  enabled: true
  plots:
    - "training_curves"
    - "confusion_matrix"
    - "segment_performance"
    - "length_distribution"
    - "error_patterns"
    - "model_comparison"
    - "acc_pwm_heatmap"  # Visualize ACC PWM
    - "acc_sequence_logo"  # Sequence logo for generated ACCs
    - "acc_score_histogram"  # Distribution of ACC PWM scores
  
  save_plots: true
  plot_dir: "./plots"

# Logging Configuration
logging:
  level: "INFO"
  log_to_file: true
  log_file: "./tempest_training.log"
  log_whitelist_usage: true
  log_generation_stats: true
  log_pwm_stats: true  # Log statistics about PWM-generated sequences

# Output Configuration
output:
  save_dir: "./tempest_output"
  save_predictions: true
  save_model: true
  save_config: true
  create_report: true
  save_acc_analysis: true  # Save detailed ACC generation analysis
